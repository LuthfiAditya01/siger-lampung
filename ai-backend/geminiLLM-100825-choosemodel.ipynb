{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfa82d16",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1765b32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import hashlib\n",
    "import pdfplumber\n",
    "import google.generativeai as genai\n",
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
    "from google.api_core import exceptions as google_exceptions\n",
    "from IPython.display import display, Markdown  # Untuk Jupyter/Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d034b8a1",
   "metadata": {},
   "source": [
    "### Cek & Updates Manifest Files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c87ae276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_file_hash(filepath):\n",
    "    \"\"\"Menghitung hash MD5 dari sebuah file untuk mendeteksi perubahan.\"\"\"\n",
    "    hash_md5 = hashlib.md5()\n",
    "    try:\n",
    "        with open(filepath, \"rb\") as f:\n",
    "            for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "                hash_md5.update(chunk)\n",
    "        return hash_md5.hexdigest()\n",
    "    except IOError:\n",
    "        return None\n",
    "\n",
    "def update_combined_txt(pdf_folder, combined_txt_path, manifest_path):\n",
    "    \"\"\"\n",
    "    Memperbarui file teks gabungan secara cerdas dengan hanya memproses\n",
    "    file PDF yang baru atau yang telah diubah.\n",
    "    \"\"\"\n",
    "    print(\"ğŸ”„ Memulai proses pembaruan cerdas...\")\n",
    "    \n",
    "    # 1. Muat manifest/catatan yang ada\n",
    "    try:\n",
    "        with open(manifest_path, 'r') as f:\n",
    "            manifest = json.load(f)\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        manifest = {}  # Buat manifest baru jika tidak ada atau korup\n",
    "\n",
    "    all_pdfs = [f for f in os.listdir(pdf_folder) if f.lower().endswith('.pdf')]\n",
    "    anything_updated = False\n",
    "    \n",
    "    # 2. Buka file teks gabungan dalam mode 'append' (tambahkan di akhir)\n",
    "    with open(combined_txt_path, 'a', encoding='utf-8') as combined_file:\n",
    "        for pdf_filename in all_pdfs:\n",
    "            pdf_path = os.path.join(pdf_folder, pdf_filename)\n",
    "            current_hash = calculate_file_hash(pdf_path)\n",
    "\n",
    "            # 3. Cek apakah file ini baru atau berubah\n",
    "            if manifest.get(pdf_filename) != current_hash:\n",
    "                print(f\"âš™ï¸  Terdeteksi file baru/berubah: '{pdf_filename}'. Memproses...\")\n",
    "                anything_updated = True\n",
    "                \n",
    "                try:\n",
    "                    text = \"\"\n",
    "                    with pdfplumber.open(pdf_path) as pdf:\n",
    "                        for page in pdf.pages:\n",
    "                            page_text = page.extract_text()\n",
    "                            if page_text:\n",
    "                                text += page_text + \"\\n\"\n",
    "                    \n",
    "                    combined_file.write(f\"\\n\\n--- MULAI DOKUMEN: {pdf_filename} ---\\n\\n\")\n",
    "                    combined_file.write(text)\n",
    "                    combined_file.write(f\"\\n\\n--- AKHIR DOKUMEN: {pdf_filename} ---\\n\\n\")\n",
    "                    \n",
    "                    manifest[pdf_filename] = current_hash\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"âŒ Gagal memproses {pdf_filename}: {e}\")\n",
    "\n",
    "    # 4. Simpan kembali manifest yang sudah diperbarui\n",
    "    with open(manifest_path, 'w') as f:\n",
    "        json.dump(manifest, f, indent=4)\n",
    "        \n",
    "    if not anything_updated and os.path.exists(combined_txt_path):\n",
    "        print(\"âœ… Tidak ada pembaruan. File data sudah yang terbaru.\")\n",
    "    else:\n",
    "        print(\"âœ¨ Proses pembaruan selesai! File data telah diperbarui.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae081ca",
   "metadata": {},
   "source": [
    "### Function Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c147d250",
   "metadata": {},
   "source": [
    "#### Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a5303d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### BARU ### Daftar model yang bisa digunakan sebagai pilihan fallback\n",
    "AVAILABLE_MODELS = [\n",
    "    \"models/gemini-2.5-pro\",\n",
    "    \"models/gemini-2.5-flash\",\n",
    "    \"models/gemini-2.0-flash\",\n",
    "    \"models/gemini-2.0-flash-001\",\n",
    "    \"models/gemini-2.0-flash-lite-001\",\n",
    "    \"models/gemini-2.0-flash-lite\",\n",
    "    \"models/gemini-1.5-flash\", \n",
    "    \"models/gemini-1.5-pro\",  \n",
    "    \"models/gemini-1.5-flash-latest\"\n",
    "]\n",
    "\n",
    "PROMPT_TEMPLATES = {\n",
    "    \"single_chunk_qa\": \"\"\"Anda adalah Asisten AI Analis Dokumen yang sangat teliti.\n",
    "                        Aturan utama Anda:\n",
    "                        1. JAWAB HANYA berdasarkan informasi dari <dokumen> yang diberikan.\n",
    "                        2. JANGAN menambahkan informasi, asumsi, atau pengetahuan eksternal.\n",
    "                        3. Jawaban harus dalam Bahasa Indonesia yang ringkas dan jelas.\n",
    "                        4. Batasi jawaban Anda MAKSIMAL 200 Kata saja.\n",
    "                        5. Jika informasi tidak ditemukan dalam dokumen, jawab dengan: \"Informasi tidak ditemukan dalam sumber yang dimiliki\"\n",
    "\n",
    "                        <dokumen>\n",
    "                        {chunk}\n",
    "                        </dokumen>\n",
    "\n",
    "                        Pertanyaan: {user_question}\n",
    "\n",
    "                        Jawaban Langsung dan Ringkas:\"\"\",\n",
    "\n",
    "    \"extractor\": \"\"\"Anda adalah Asisten AI yang handal dalam mengekstraksi dokumen yang diberikan. Dari bagian dokumen berikut ekstrak semua informasi yang relevan dengan\n",
    "                    pertanyaan: \"{user_question}\". Fokus hanya pada informasi yang ada pada dokumen dan menjawab pertanyaan. Jika tidak ada yang relevan katakan \"Tidak ada informasi yang relevan\".\n",
    "                    Kemudian jika pertanyaan: \"{user_question}\" berupa slang indonesia seperti ucapan terimakasih atau tidak ada keterkaitannya dengan informasi pada sumber maka cukup katakan\n",
    "                    \"Saya sulit memahami pertanyaan anda\".\n",
    "\n",
    "                    <dokumen_bagian>\n",
    "                    {chunk}\n",
    "                    </dokumen_bagian>\n",
    "\n",
    "                    Informasi Relevan:\"\"\",\n",
    "\n",
    "    \"synthesizer\": \"\"\"Anda adalah asisten AI yang ahli dalam merangkum informasi. Berdasarkan kumpulan informasi berikut, maka rangkum informasi tersebut sehingga menjawab pertanyaan pengguna.\n",
    "                    Perlu diingat Aturan utama yang harus anda penuhi :\n",
    "                    1. Gabungkan informasi yang relevan dan ringkas untuk memberikan jawaban yang padu dan relevan dengan pertanyaan.\n",
    "                    2. Jawaban harus dalam Bahasa Indonesia yang jelas dan menyesuaikan gaya bahasa pengguna.\n",
    "                    3. JAWAB SECARA LANGSUNG dan SINGKAT, hindari menggunakan kalimat pembuka atau penutup yang tidak perlu.\n",
    "                    4. Batasi jawaban anda tidak lebih dari 200 kata, kecuali diminta.\n",
    "                        <informasi_terkumpul>\n",
    "                        {combined_info}\n",
    "                        </informasi_terkumpul>\n",
    "                        Pertanyaan Pengguna: {user_question}\n",
    "                        Jawaban Akhir yang Ringkas:\"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96aa52eb",
   "metadata": {},
   "source": [
    "#### Chatbot Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8a279a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TxtChatbot:\n",
    "    # ### Inisialisasi diubah untuk menerima daftar model dan konfigurasi\n",
    "    def __init__(self, model_names: list, generation_config: dict, safety_settings: dict):\n",
    "        \"\"\"Inisialisasi Chatbot dengan daftar model untuk fallback.\"\"\"\n",
    "        self.model_names = model_names\n",
    "        self.generation_config = generation_config\n",
    "        self.safety_settings = safety_settings\n",
    "        self.models = self._initialize_models()\n",
    "        self.current_model_index = 0\n",
    "        self.source_text = None\n",
    "        self.data_source_name = None\n",
    "\n",
    "        \n",
    "        if self.models:\n",
    "            print(f\"âœ… TxtChatbot berhasil diinisialisasi dengan model utama: '{self.models[0].model_name}'!\")\n",
    "        else:\n",
    "            print(\"âŒ Gagal menginisialisasi model. Pastikan nama model dan API key valid.\")\n",
    "\n",
    "    # ### Fungsi untuk membuat objek model dari daftar nama\n",
    "    def _initialize_models(self):\n",
    "        \"\"\"Membuat instance model generatif untuk setiap nama model.\"\"\"\n",
    "        models = []\n",
    "        for name in self.model_names:\n",
    "            try:\n",
    "                model = genai.GenerativeModel(\n",
    "                    model_name=name,\n",
    "                    generation_config=self.generation_config,\n",
    "                    safety_settings=self.safety_settings\n",
    "                )\n",
    "                models.append(model)\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ Peringatan: Gagal memuat model '{name}'. Error: {e}\")\n",
    "        return models\n",
    "        \n",
    "    def load_from_combined_txt(self, combined_txt_path):\n",
    "        self.data_source_name = os.path.basename(combined_txt_path)\n",
    "        print(f\"ğŸ“‚ Membaca sumber data utama dari: '{self.data_source_name}'\")\n",
    "        try:\n",
    "            with open(combined_txt_path, 'r', encoding='utf-8') as f:\n",
    "                self.source_text = f.read()\n",
    "            if not self.source_text.strip():\n",
    "                print(\"âš ï¸ Peringatan: File sumber data kosong.\")\n",
    "                return False\n",
    "            print(\"âœ… Sumber data berhasil dimuat.\")\n",
    "            return True\n",
    "        except FileNotFoundError:\n",
    "            print(f\"âŒ File sumber data tidak ditemukan.\")\n",
    "            return False\n",
    "\n",
    "    def get_info(self):\n",
    "        if not self.source_text:\n",
    "            print(\"âŒ Belum ada data yang dimuat.\")\n",
    "            return\n",
    "        lines = self.source_text.count('\\n') + 1\n",
    "        words = len(self.source_text.split())\n",
    "        chars = len(self.source_text)\n",
    "        info = (f\"**ğŸ“Š INFORMASI SUMBER DATA**\\n\"\n",
    "                f\"- ğŸ“„ **Sumber:** {self.data_source_name}\\n\"\n",
    "                f\"- ğŸ“ **Total karakter:** {chars:,}\\n\"\n",
    "                f\"- ğŸ—£ï¸ **Total kata:** {words:,}\\n\"\n",
    "                f\"- ğŸ“„ **Total baris:** {lines:,}\")\n",
    "        try:\n",
    "            display(Markdown(info))\n",
    "        except NameError:\n",
    "            print(info.replace('**', ''))\n",
    "            \n",
    "\n",
    "    def chunk_text(self, text, max_length=100000):\n",
    "        if len(text) <= max_length:\n",
    "            return [text]\n",
    "        \n",
    "        chunks, words = [], text.split()\n",
    "        current_chunk, current_length = [], 0\n",
    "        for word in words:\n",
    "            word_length = len(word) + 1\n",
    "            if current_length + word_length > max_length:\n",
    "                if current_chunk: chunks.append(\" \".join(current_chunk))\n",
    "                current_chunk, current_length = [word], word_length\n",
    "            else:\n",
    "                current_chunk.append(word)\n",
    "                current_length += word_length\n",
    "        if current_chunk: chunks.append(\" \".join(current_chunk))\n",
    "        print(f\"ğŸ“ Teks sumber terlalu besar, dibagi menjadi {len(chunks)} bagian untuk dianalisis.\")\n",
    "        return chunks\n",
    "    \n",
    "    # ### Logika switching/fallback model\n",
    "    def _switch_to_next_model(self):\n",
    "        \"\"\"Beralih ke model berikutnya dalam daftar jika tersedia.\"\"\"\n",
    "        next_index = self.current_model_index + 1\n",
    "        if next_index < len(self.models):\n",
    "            self.current_model_index = next_index\n",
    "            print(f\"ğŸ”„ Beralih ke model fallback: {self.models[self.current_model_index].model_name}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"âŒ Semua model telah dicoba dan gagal.\")\n",
    "            return False\n",
    "\n",
    "    # ### Fungsi _call_model dimodifikasi secara signifikan\n",
    "    def _call_model(self, prompt: str, is_retry=False) -> str:\n",
    "        \"\"\"\n",
    "        Memanggil model, menangani error spesifik, dan mencoba fallback.\n",
    "        \"\"\"\n",
    "        if not self.models:\n",
    "            return \"âŒ Tidak ada model yang berhasil diinisialisasi.\"\n",
    "        \n",
    "        # Atur ulang ke model utama jika ini adalah permintaan baru\n",
    "        if not is_retry:\n",
    "            self.current_model_index = 0\n",
    "\n",
    "        current_model = self.models[self.current_model_index]\n",
    "        print(f\"ğŸ§  Mencoba menghasilkan respons dengan model: {current_model.model_name}...\")\n",
    "        \n",
    "        try:\n",
    "            response = current_model.generate_content(prompt)\n",
    "            \n",
    "            # ### Bagian pelacakan token dihapus ###\n",
    "            \n",
    "            return response.text if response.parts else \"âŒ Respons diblokir oleh filter keamanan.\"\n",
    "\n",
    "        except google_exceptions.ResourceExhausted as e:\n",
    "            print(f\"âš ï¸ Model '{current_model.model_name}' mencapai limit penggunaan.\")\n",
    "            if self._switch_to_next_model():\n",
    "                return self._call_model(prompt, is_retry=True) # Coba lagi dengan model baru\n",
    "            else:\n",
    "                return \"Tanya DTSEN belum dapat digunakan kembali karena telah mencapai limit penggunaan. Mohon untuk mencoba beberapa saat lagi.\"\n",
    "\n",
    "        except (google_exceptions.InternalServerError, google_exceptions.ServiceUnavailable) as e:\n",
    "            print(f\"âŒ Terjadi gangguan server pada model '{current_model.model_name}'.\")\n",
    "            if self._switch_to_next_model():\n",
    "                return self._call_model(prompt, is_retry=True) # Coba lagi dengan model baru\n",
    "            else:\n",
    "                return \"Maaf, layanan sedang mengalami gangguan teknis. Silakan coba lagi nanti.\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Terjadi kesalahan tak terduga dengan model '{current_model.model_name}': {e}\")\n",
    "            if self._switch_to_next_model():\n",
    "                 return self._call_model(prompt, is_retry=True) # Coba lagi dengan model baru\n",
    "            else:\n",
    "                return f\"Maaf, terjadi kesalahan yang tidak dapat diatasi setelah mencoba semua model.\"\n",
    "\n",
    "    def get_response(self, user_question: str) -> str:\n",
    "        if not self.source_text:\n",
    "            return \"âŒ Belum ada data yang dimuat. Harap jalankan `load_from_combined_txt` terlebih dahulu.\"\n",
    "        \n",
    "        print(f\"ğŸ¤– Memproses pertanyaan: {user_question}\")\n",
    "        chunks = self.chunk_text(self.source_text)\n",
    "        \n",
    "        if len(chunks) == 1:\n",
    "            prompt = PROMPT_TEMPLATES[\"single_chunk_qa\"].format(chunk=chunks[0], user_question=user_question)\n",
    "            return self._call_model(prompt)\n",
    "        else:\n",
    "            relevant_info = []\n",
    "            print(f\"ğŸ“Š Menganalisis {len(chunks)} bagian teks...\")\n",
    "            for i, chunk in enumerate(chunks):\n",
    "                print(f\"â³ Mengekstrak info dari bagian {i+1}/{len(chunks)}...\", end='\\r')\n",
    "                extract_prompt = PROMPT_TEMPLATES[\"extractor\"].format(user_question=user_question, chunk=chunk)\n",
    "                response_text = self._call_model(extract_prompt)\n",
    "                \n",
    "                if \"belum dapat digunakan kembali\" in response_text or \"mengalami gangguan teknis\" in response_text:\n",
    "                    return response_text # Langsung hentikan jika ada error fatal\n",
    "\n",
    "                if response_text and \"tidak ada informasi relevan\" not in response_text.lower():\n",
    "                    relevant_info.append(response_text)\n",
    "            \n",
    "            print(\"\\nâœ… Ekstraksi selesai.\")\n",
    "            if not relevant_info:\n",
    "                return \"Informasi yang relevan dengan pertanyaan Anda tidak ditemukan di dalam dokumen.\"\n",
    "            \n",
    "            combined_info = \"\\n\\n---\\n\\n\".join(relevant_info)\n",
    "            synthesis_prompt = PROMPT_TEMPLATES[\"synthesizer\"].format(combined_info=combined_info, user_question=user_question)\n",
    "            \n",
    "            print(\"âœï¸  Merangkum informasi untuk jawaban akhir...\")\n",
    "            return self._call_model(synthesis_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0677dc9",
   "metadata": {},
   "source": [
    "### Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "36f60af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… API Key berhasil dikonfigurasi!\n",
      "\n",
      "==================================================\n",
      "âœ… TxtChatbot berhasil diinisialisasi dengan model utama: 'models/gemini-2.5-pro'!\n",
      "ğŸ“‚ Membaca sumber data utama dari: 'combined.txt'\n",
      "âœ… Sumber data berhasil dimuat.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Ganti dengan API Key Anda\n",
    "    API_KEY = \"AIzaSyAXMr24XVP1ohfCO29GdM-9nm1IpBF_A_o\"\n",
    "    \n",
    "    try:\n",
    "        genai.configure(api_key=API_KEY)\n",
    "        print(\"âœ… API Key berhasil dikonfigurasi!\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Gagal mengkonfigurasi API Key: {e}\")\n",
    "        exit()\n",
    "\n",
    "    my_generation_config = {\n",
    "        \"temperature\": 0.5,\n",
    "        \"max_output_tokens\": 4096,\n",
    "        \"top_p\": 0.6\n",
    "    }\n",
    "    my_safety_settings = {\n",
    "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_ONLY_HIGH,\n",
    "    }\n",
    "\n",
    "    # Ganti dengan path ke file teks Anda\n",
    "    combined_txt_path = \"/Users/ptrayoga/Library/CloudStorage/GoogleDrive-hitmeup.yogaputra@gmail.com/My Drive/4. Improvement/9. BPS Code/11. LLM/Files/chatbot_data/combined.txt\"\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    # ### BARU ### Inisialisasi chatbot dengan daftar model dan konfigurasi\n",
    "    chatbot = TxtChatbot(\n",
    "        model_names=AVAILABLE_MODELS,\n",
    "        generation_config=my_generation_config,\n",
    "        safety_settings=my_safety_settings\n",
    "    )\n",
    "    success = chatbot.load_from_combined_txt(combined_txt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f055e8",
   "metadata": {},
   "source": [
    "### Testing Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24dc3aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**ğŸ“Š INFORMASI SUMBER DATA**\n",
       "- ğŸ“„ **Sumber:** combined.txt\n",
       "- ğŸ“ **Total karakter:** 151,532\n",
       "- ğŸ—£ï¸ **Total kata:** 20,611\n",
       "- ğŸ“„ **Total baris:** 835"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ¤– Memproses pertanyaan: apa itu DTSEN?\n",
      "ğŸ“ Teks sumber terlalu besar, dibagi menjadi 2 bagian untuk dianalisis.\n",
      "ğŸ“Š Menganalisis 2 bagian teks...\n",
      "ğŸ§  Mencoba menghasilkan respons dengan model: models/gemini-2.5-pro...\n"
     ]
    }
   ],
   "source": [
    "if success:\n",
    "    chatbot.get_info()\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    \n",
    "    question = \"apa itu DTSEN?\"\n",
    "    answer = chatbot.get_response(question)\n",
    "    \n",
    "    print(f\"\\nâ“ Pertanyaan: {question}\")\n",
    "    print(\"ğŸ¤– Jawaban:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(answer)\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    \n",
    "else:\n",
    "    print(\"\\nâš ï¸ Gagal memuat data. Chatbot tidak dapat digunakan.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fa8829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**ğŸ“Š INFORMASI SUMBER DATA**\n",
       "- ğŸ“„ **Sumber:** combined.txt\n",
       "- ğŸ“ **Total karakter:** 151,532\n",
       "- ğŸ—£ï¸ **Total kata:** 20,611\n",
       "- ğŸ“„ **Total baris:** 835"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ¤– Memproses pertanyaan: jelaskan apa itu desil 1 dan 10?\n",
      "ğŸ“ Teks sumber terlalu besar, dibagi menjadi 2 bagian untuk dianalisis.\n",
      "ğŸ“Š Menganalisis 2 bagian teks...\n",
      "ğŸ§  Mencoba menghasilkan respons dengan model: models/gemini-2.5-pro...\n",
      "ğŸ§  Mencoba menghasilkan respons dengan model: models/gemini-2.5-pro...\n",
      "\n",
      "âœ… Ekstraksi selesai.\n",
      "âœï¸  Merangkum informasi untuk jawaban akhir...\n",
      "ğŸ§  Mencoba menghasilkan respons dengan model: models/gemini-2.5-pro...\n",
      "\n",
      "â“ Pertanyaan: jelaskan apa itu desil 1 dan 10?\n",
      "ğŸ¤– Jawaban:\n",
      "----------------------------------------\n",
      "Desil 1 adalah kelompok dengan tingkat kesejahteraan terendah, yang dikategorikan sebagai \"Miskin Ekstrem\" dan \"Miskin\". Kelompok ini menjadi sasaran utama berbagai program bantuan sosial pemerintah, seperti Program Keluarga Harapan (PKH), Bantuan Pangan Non-Tunai (Sembako), dan Penerima Bantuan Iuran Jaminan Kesehatan (PBI JK).\n",
      "\n",
      "Sebaliknya, Desil 10 adalah kelompok dengan tingkat kesejahteraan tertinggi. Kelompok ini dianggap sudah mampu dan tidak lagi layak menerima bantuan sosial. Oleh karena itu, mereka yang masuk dalam desil ini akan dikeluarkan dari program bantuan atau disebut telah \"graduasi\".\n"
     ]
    }
   ],
   "source": [
    "if success:\n",
    "    chatbot.get_info()\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    \n",
    "    question = \"jelaskan apa itu desil 1 dan 10?\"\n",
    "    answer = chatbot.get_response(question)\n",
    "    \n",
    "    print(f\"\\nâ“ Pertanyaan: {question}\")\n",
    "    print(\"ğŸ¤– Jawaban:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(answer)\n",
    "else:\n",
    "    print(\"\\nâš ï¸ Gagal memuat data. Chatbot tidak dapat digunakan.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e464edd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**ğŸ“Š INFORMASI SUMBER DATA**\n",
       "- ğŸ“„ **Sumber:** combined.txt\n",
       "- ğŸ“ **Total karakter:** 151,532\n",
       "- ğŸ—£ï¸ **Total kata:** 20,611\n",
       "- ğŸ“„ **Total baris:** 835"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "ğŸ¤– Memproses pertanyaan: siapa yang terlibat di DTSEN?\n",
      "ğŸ“ Teks sumber terlalu besar, dibagi menjadi 2 bagian untuk dianalisis.\n",
      "ğŸ“Š Menganalisis 2 bagian teks...\n",
      "ğŸ§  Mencoba menghasilkan respons dengan model: models/gemini-2.5-pro...\n",
      "ğŸ§  Mencoba menghasilkan respons dengan model: models/gemini-2.5-pro...\n",
      "\n",
      "âœ… Ekstraksi selesai.\n",
      "âœï¸  Merangkum informasi untuk jawaban akhir...\n",
      "ğŸ§  Mencoba menghasilkan respons dengan model: models/gemini-2.5-pro...\n",
      "\n",
      "â“ Pertanyaan: siapa yang terlibat di DTSEN?\n",
      "ğŸ¤– Jawaban:\n",
      "----------------------------------------\n",
      "Pihak yang terlibat dalam Data Tunggal Sosial dan Ekonomi Nasional (DTSEN) mencakup berbagai tingkatan, yaitu:\n",
      "\n",
      "1.  **Pemerintah Pusat:** Peran utama dipegang oleh **Badan Pusat Statistik (BPS)** sebagai pengelola dan penyusun data, serta **Kementerian Sosial (Kemensos)** sebagai pengguna utama dan verifikator untuk bantuan sosial. Lembaga lain yang mendukung adalah **Kementerian Dalam Negeri (Dukcapil)** yang menyediakan data kependudukan, **Bappenas** yang menyusun pedoman, dan **BPKP** yang melakukan pengawasan.\n",
      "\n",
      "2.  **Pemerintah Daerah:** **Pemerintah Daerah (Bupati/Walikota)** dan **Dinas Sosial** melakukan verifikasi dan validasi usulan data. Di tingkat paling bawah, **aparat desa/kelurahan (Kepala Desa/Lurah, RT/RW)** berperan penting dalam mengusulkan data melalui musyawarah.\n",
      "\n",
      "3.  **Pihak Lain:** **Masyarakat** dapat berpartisipasi dengan mengusulkan atau menyanggah data. **Badan Usaha (PLN, Pertamina)** dan **BPJS** digunakan sebagai sumber data pembanding, sementara **petugas lapangan** seperti Pendamping PKH membantu dalam proses verifikasi lapangan.\n"
     ]
    }
   ],
   "source": [
    "if success:\n",
    "    chatbot.get_info()\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    \n",
    "    question = \"siapa yang terlibat di DTSEN?\"\n",
    "    answer = chatbot.get_response(question)\n",
    "    \n",
    "    print(f\"\\nâ“ Pertanyaan: {question}\")\n",
    "    print(\"ğŸ¤– Jawaban:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(answer)\n",
    "else:\n",
    "    print(\"\\nâš ï¸ Gagal memuat data. Chatbot tidak dapat digunakan.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
